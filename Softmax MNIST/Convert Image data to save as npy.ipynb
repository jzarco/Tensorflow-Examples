{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from image_reader_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data = \"D:\\\\Image Data\\\\fruits-360\\\\Training\"\n",
    "testing_data = \"D:\\\\Image Data\\\\fruits-360\\\\Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train,Y_train = build_imgdata_from_dirs(training_data)\n",
    "X_test, Y_test = build_imgdata_from_dirs(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"X train shape: \",X_train.shape)\n",
    "print(\"X test shape: \",X_test.shape)\n",
    "print(\"Y train shape: \",Y_train.shape)\n",
    "print(\"Y test shape: \",Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"D:\\\\Image Data\\\\Data\\\\X_train.npy\",X_train)\n",
    "np.save(\"D:\\\\Image Data\\\\Data\\\\Y_train.npy\",Y_train)\n",
    "np.save(\"D:\\\\Image Data\\\\Data\\\\X_test.npy\",X_test)\n",
    "np.save(\"D:\\\\Image Data\\\\Data\\\\Y_test.npy\",Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from image_reader_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.framework import ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_placeholders(n_h,n_w,n_c,n_y):\n",
    "\n",
    "    X = tf.placeholder(tf.float32, shape=[None, n_h, n_w, n_c])\n",
    "    Y = tf.placeholder(tf.float32, shape=[None, n_y])\n",
    "\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = create_placeholders(100,100,3,103)\n",
    "\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_parameters():\n",
    "    ######################################\n",
    "    \"\"\"BUILD FILTERS WITH BIASES\"\"\"\n",
    "    ######################################\n",
    "    \"\"\"\n",
    "    Filters should be of shape height, width, and number of channels with defined total number of filters. \n",
    "    e.g. [4,4,3,32] defines a 4x4 filter for a 3 channel input that outputs 32 channels.\n",
    "    \"\"\"\n",
    "    F1 = tf.get_variable('F1', shape=[4, 4, 3, 32], initializer=tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    fb1 = tf.get_variable('fb1', shape=[32], initializer=tf.zeros_initializer())\n",
    "\n",
    "    F2 = tf.get_variable('F2', shape=[4, 4, 32, 64], initializer=tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    fb2 = tf.get_variable('fb2', shape=[64], initializer=tf.zeros_initializer())\n",
    "\n",
    "    F3 = tf.get_variable('F3', shape=[4, 4, 64, 128], initializer=tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    fb3 = tf.get_variable('fb3', shape=[128], initializer=tf.zeros_initializer())\n",
    "\n",
    "    ######################################\n",
    "    \"\"\"BUILD WEIGHTS WITH BIASES FOR FULLY CONNECTED LAYERS\"\"\"\n",
    "    ######################################\n",
    "\n",
    "    b1 = tf.get_variable('b1', shape=[1024, 1], initializer=tf.zeros_initializer())\n",
    "\n",
    "    W2 = tf.get_variable('W2', shape=[512, 1024], initializer=tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b2 = tf.get_variable('b2', shape=[512, 1], initializer=tf.zeros_initializer())\n",
    "\n",
    "    W3 = tf.get_variable('W3', shape=[10, 512], initializer=tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b3 = tf.get_variable('b3', shape=[10, 1], initializer=tf.zeros_initializer())\n",
    "\n",
    "    ######################################\n",
    "    \"\"\"STORE FILTERS AND WEIGHTS \"\"\"\n",
    "    ######################################\n",
    "    parameters = {'F1': F1,\n",
    "                  'fb1': fb1,\n",
    "                  'F2': F2,\n",
    "                  'fb2': fb2,\n",
    "                  'F3': F3,\n",
    "                  'fb3': fb3,\n",
    "                  'b1': b1,\n",
    "                  'W2': W2,\n",
    "                  'b2': b2,\n",
    "                  'W3': W3,\n",
    "                  'b3': b3}\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = build_parameters()\n",
    "print(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, b, filter, strides=1, padding='SAME'):\n",
    "    x = tf.nn.conv2d(x, filter, strides=[1, strides, strides, 1], padding=padding)\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    x = tf.nn.relu(x)\n",
    "    return x\n",
    "\n",
    "def maxpool2d(x, k=2, padding='SAME'):\n",
    "    x = tf.nn.max_pool(x, ksize=[1, k, k, 1],strides=[1, k, k, 1], padding=padding)\n",
    "    return x\n",
    "\n",
    "def dropout(x, prob):\n",
    "    x = tf.nn.dropout(x, prob)\n",
    "    return x\n",
    "\n",
    "def dense(x, W, b):\n",
    "    x = tf.add(tf.matmul(W, x), b)\n",
    "    x = tf.nn.relu(x)\n",
    "    return x\n",
    "\n",
    "def flatten(x):\n",
    "    x = tf.layers.flatten(x)\n",
    "    return x\n",
    "\n",
    "def one_hot_mat(y, n_classes):\n",
    "    \"\"\"\n",
    "\n",
    "    :param y: label vector\n",
    "    :param n_classes: number of different classes\n",
    "    :return: one hot tensorflow matrix\n",
    "    \"\"\"\n",
    "\n",
    "    n_c = tf.constant(n_classes, name='n_classes')\n",
    "\n",
    "    one_hot_mat = tf.one_hot(y, depth=n_c, axis=0)\n",
    "\n",
    "    sess = tf.Session()\n",
    "\n",
    "    one_hot = sess.run(one_hot_mat)\n",
    "\n",
    "    sess.close()\n",
    "\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convnet(X, parameters, keep_prob):\n",
    "\n",
    "    ####FIRST CONVOLUTION LAYER####\n",
    "    conv1 = conv2d(X, parameters['fb1'], parameters['F1'], strides=1, padding='SAME')\n",
    "    conv1 = maxpool2d(conv1, k=3)\n",
    "\n",
    "    ####SECOND CONVOLUTION LAYER####\n",
    "    conv2 = conv2d(conv1, parameters['fb2'], parameters['F2'], strides=1, padding='SAME')\n",
    "    conv2 = maxpool2d(conv2, k=3)\n",
    "\n",
    "    ####THIRD CONVOLUTION LAYER####\n",
    "    conv3 = conv2d(conv2, parameters['fb3'], parameters['F3'], strides=1, padding='SAME')\n",
    "    conv3 = maxpool2d(conv3, k=3)\n",
    "\n",
    "    ####FULLY CONNECTED LAYERS####\n",
    "    fc1 = flatten(conv3)\n",
    "    \n",
    "    d1 = tf.keras.layers.Dense(1024)(fc1)\n",
    "    d1 = dropout(d1, keep_prob)\n",
    "    d2 = dense(d1, parameters['W2'], parameters['b2'])\n",
    "    d2 = dropout(d2, keep_prob)\n",
    "    out = dense(d2, parameters['W3'], parameters['b3'])\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X_train,Y_train,X_test,Y_test,epochs=15,batch_size=5,learning_rate=0.001):\n",
    "\n",
    "    ops.reset_default_graph()\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(123)\n",
    "\n",
    "    m, n_h, n_w, n_c = X_train.shape #Number of training examples\n",
    "    n_y = Y_train.shape[1]\n",
    "\n",
    "    costs = []\n",
    "\n",
    "    ######################################\n",
    "    \"\"\"CREATE PLACEHOLDER FOR GRAPH INPUT\"\"\"\n",
    "    ######################################\n",
    "\n",
    "    X,Y = create_placeholders(n_h,n_w,n_c,n_y)\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "    parameters = build_parameters()\n",
    "\n",
    "    ######################################\n",
    "    \"\"\"BUILD PREDICTIONS AND CHECK PREDICTIONS AND DEFINE OPTIMIZATION\"\"\"\n",
    "    ######################################\n",
    "\n",
    "    logits = convnet(X, parameters, keep_prob)\n",
    "    predictions = tf.nn.softmax(logits)\n",
    "\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "    evaluate = tf.equal(tf.argmax(predictions,1), tf.argmax(Y,1))\n",
    "\n",
    "    accuracy = tf.reduce_mean(tf.cast(evaluate, tf.float32))\n",
    "\n",
    "    ######################################\n",
    "    \"\"\"INITIALIZE TENSORS AND BEGIN TRAINING\"\"\"\n",
    "    ######################################\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        sess.run(init)\n",
    "        print(\"Shuffled shape: \",X_train.shape)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            epoch = epoch + 1\n",
    "            epoch_cost = 0\n",
    "            mb_costs = []\n",
    "\n",
    "            total_batches = int(m / batch_size)\n",
    "\n",
    "            if m % batch_size == 0:\n",
    "                for batch_num in range(total_batches):\n",
    "                    X_batch = X_shuffled[batch_num * batch_size:batch_num * batch_size + batch_size,:,:,:]\n",
    "                    Y_batch = Y_shuffled[batch_num * batch_size:batch_num * batch_size + batch_size,:]\n",
    "\n",
    "                    _, mb_cost = sess.run([opt, cost], feed_dict={X: X_batch, Y: Y_batch, keep_prob: 0.8})\n",
    "                    mb_costs.append(mb_cost)\n",
    "\n",
    "                    epoch_cost += mb_cost / total_batches\n",
    "                plt.plot(np.squeeze(mb_costs))\n",
    "                plt.title(\"Minibatch Costs\")\n",
    "                plt.show()\n",
    "            else:\n",
    "                for batch_num in range(total_batches):\n",
    "                    try:\n",
    "                        X_batch = X_shuffled[batch_num * batch_size:batch_num * batch_size + batch_size,:,:,:]\n",
    "                        Y_batch = Y_shuffled[batch_num * batch_size:batch_num * batch_size + batch_size,:]\n",
    "                    except:\n",
    "                        try:\n",
    "                            X_batch = X_shuffled[batch_num * batch_size:batch_num * batch_size + batch_size,:,:,:]\n",
    "                            Y_batch = Y_shuffled[batch_num * batch_size:batch_num * batch_size + batch_size,:]\n",
    "                        except:\n",
    "                            print(\"Error slicing minibatches\")\n",
    "                    _, mb_cost = sess.run([opt, cost], feed_dict={X: X_batch, Y: Y_batch, keep_prob: 0.8})\n",
    "                    plt.plot(np.squeeze(mb_costs))\n",
    "                    plt.title(\"Minibatch Costs\")\n",
    "                    plt.show()\n",
    "\n",
    "                    epoch_cost += mb_cost/total_batches\n",
    "            if (print_cost == True) and (epoch % 5 == 0):\n",
    "                print(\"Total Cost at Epoch {epoch}: {cost}\".format(epoch=epoch,cost=epoch_cost))\n",
    "            costs.append(epoch_cost)\n",
    "\n",
    "        parameters = sess.run(parameters)\n",
    "\n",
    "        print(\"Train Accuracy: \", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print(\"Test Accuracy: \", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "\n",
    "        return parameters,costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"D:\\\\Image Data\\\\Data\\\\X_train.npy\")\n",
    "X_test = np.load(\"D:\\\\Image Data\\\\Data\\\\X_test.npy\")\n",
    "Y_train = np.load(\"D:\\\\Image Data\\\\Data\\\\Y_train.npy\")\n",
    "Y_test = np.load(\"D:\\\\Image Data\\\\Data\\\\Y_test.npy\")\n",
    "\n",
    "n_c = len(np.unique(Y_train))\n",
    "\n",
    "Y_train = one_hot_mat(Y_train, n_c).T\n",
    "Y_test = one_hot_mat(Y_test, n_c).T\n",
    "\n",
    "print(\"Shape of Y: \", Y_train.shape)\n",
    "print(\"Shape of X: \",X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffler = np.random.permutation(X_train.shape[0])\n",
    "X_train = X_train[shuffler,:,:,:]\n",
    "Y_train = Y_train[shuffler,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, cost = model(X_train, Y_train, X_test, Y_test, epochs=15, batch_size=5, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
